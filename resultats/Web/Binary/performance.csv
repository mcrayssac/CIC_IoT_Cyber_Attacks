Model,Accuracy Training,Recall Training,Precision Training,F1 Training,Accuracy Testing,Recall Testing,Precision Testing,F1 Testing,FU_rate,FL_rate,FU,FL,Total rows
XGB,0.997142395206548,0.9395621269271186,0.9937754707152586,0.9650218852059076,0.9934647078044976,0.8794498771575563,0.9648353630060256,0.9176228144993795,0.0011776467124568,0.0053576454830454,364,1656,309091
DT,1.0,1.0,1.0,1.0,0.9887832385931652,0.8704025706158793,0.8721411578049969,0.8712697148739003,0.0055549983661769,0.0056617630406579,1717,1750,309091
RF,1.0,1.0,1.0,1.0,0.992219119935553,0.8323827005807838,0.9862750401694468,0.8942375245748317,0.0003008822644463,0.0074799978000006,93,2312,309091
ET,1.0,1.0,1.0,1.0,0.98924265022275,0.7646125639972718,0.9843654854207466,0.840940125919001,0.0002491175737889,0.0105082322034611,77,3248,309091
Cat,0.997469646471238,0.9454591156479896,0.99567480972703,0.9691656313790358,0.9927723550669544,0.8721595806286379,0.9544736695834506,0.909023877952768,0.0015529407197233,0.0056747042133222,480,1754,309091
LIGHT,0.9943529677599068,0.8901876423013644,0.9750680345032156,0.9282737006402336,0.9919861788275944,0.852152096596121,0.9547239857122632,0.8966141867144037,0.0014429407520762,0.0065708804203292,446,2031,309091
GBoost,0.9916979470826912,0.8233482409508224,0.9789428541377794,0.8854079001510646,0.9910447085162624,0.8123889976835152,0.975528260101528,0.8763368937727642,0.0005888233562284,0.0083664681275093,182,2586,309091
Adaboost,0.9898318357042816,0.8274344840163159,0.920246184705802,0.867801382221905,0.9894141207605528,0.81672185012414,0.9221623558165776,0.8615558044989511,0.0024555875130624,0.0081302917263847,759,2513,309091
MLP,0.984484783790154,0.6788740911886867,0.9199864724849488,0.7488986758917102,0.983978828241521,0.6824372002906893,0.8995389871769828,0.7487242702957582,0.0018797053294984,0.0141414664289804,581,4371,309091

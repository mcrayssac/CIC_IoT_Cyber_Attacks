{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DoS ML System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, BaggingClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "from functions_ml import *\n",
    "model_repo = \".\\\\DoS_system\\\\\"\n",
    "file_path = '.\\Files\\\\DoS\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing data for binary classification (DoS (DDoS and DoS) or Benign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135 34\n"
     ]
    }
   ],
   "source": [
    "train_sets, test_sets = get_train_and_test_files()\n",
    "print(len(train_sets), len(test_sets))\n",
    "\n",
    "X_columns = x_columns(read_csv_file(train_sets[0]))\n",
    "y_column = 'label'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 169/169 [01:56<00:00,  1.45it/s]\n"
     ]
    }
   ],
   "source": [
    "scaler = get_or_define_and_save_scaler(model_repo, train_sets + test_sets, X_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "performance_path = 'performance.csv'\n",
    "local_path = '.\\\\DoS_system\\\\'\n",
    "after_build_csv = 'after_build_set_scaled.csv'\n",
    "\n",
    "# Get path data\n",
    "build_sets, after_build_sets = get_train_and_test_files(path_to_datasets=file_path)\n",
    "print(len(build_sets) + len(after_build_sets))\n",
    "\n",
    "# Get build datasets\n",
    "build_nb = round(len(build_sets) * 0.8)\n",
    "train_sets = build_sets[:build_nb]\n",
    "# train_sets = train_sets[: round(len(train_sets) * 0.5)]\n",
    "test_sets = build_sets[build_nb:]\n",
    "# test_sets = test_sets[: round(len(test_sets) * 0.5)]\n",
    "\n",
    "# Define different columns\n",
    "X_columns = x_columns(read_csv_file(train_sets[0], path_to_datasets=file_path))\n",
    "X_columns = X_columns[:-2]\n",
    "print(len(X_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "simpleModelsDef = [\n",
    "    {\n",
    "        \"Name\": \"DT\",\n",
    "        \"Model\": DecisionTreeClassifier(random_state = 42)\n",
    "    },\n",
    "    # {\n",
    "    #     \"Name\": \"RF\",\n",
    "    #     \"Model\": RandomForestClassifier(random_state = 42)\n",
    "    # },\n",
    "    {\n",
    "        \"Name\": \"ET\",\n",
    "        \"Model\": ExtraTreesClassifier(random_state = 42)\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"XGB\",\n",
    "        \"Model\": XGBClassifier(random_state = 42)\n",
    "    },\n",
    "    # {\n",
    "    #     \"Name\": \"Cat\",\n",
    "    #     \"Model\": CatBoostClassifier(random_state = 42, verbose = 0)\n",
    "    # },\n",
    "    # {\n",
    "    #     \"Name\": \"LIGHT\",\n",
    "    #     \"Model\": LGBMClassifier(random_state = 42)\n",
    "    # },\n",
    "    {\n",
    "        \"Name\": \"GBoost\",\n",
    "        \"Model\": GradientBoostingClassifier(random_state = 42)\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"Adaboost\",\n",
    "        \"Model\": AdaBoostClassifier(random_state = 42)\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Import or define encoder and performance dataframe\n",
    "encoder = get_or_define_encoder(model_repo)\n",
    "performance = get_or_define_performance_df(model_repo, performance_path)\n",
    "\n",
    "# # Load selected X columns\n",
    "# selected_X = pd.read_csv(model_repo+'selected_X_columns.csv').values\n",
    "\n",
    "# # Map selected X columns\n",
    "# selected_X = list(map(lambda x: x[0], selected_X))\n",
    "# print(selected_X)\n",
    "\n",
    "selected_X = X_columns\n",
    "\n",
    "# Buidling models\n",
    "plotConfusionMatrix = True\n",
    "figsizeConfusionMatrix = (10, 5)\n",
    "saveConfusionMatrix = True\n",
    "for model in tqdm(simpleModelsDef):\n",
    "    # Build model\n",
    "    performance, encoder = build_model_multifiltered(model['Model'], ''+model['Name'], train_sets, test_sets, file_path, performance, model_repo+'', X_columns=selected_X, y_column=y_column, encoder=encoder, scaler=scaler, \\\n",
    "                                                     confusionMatrix=plotConfusionMatrix, saving=saveConfusionMatrix, pathToSave=model_repo+''+model['Name'], figsize=figsizeConfusionMatrix, modelLabel=model['Name'])\n",
    "\n",
    "    # Save performance\n",
    "    performance.to_csv(model_repo + performance_path, index=False)\n",
    "\n",
    "# Save the encoder to a file\n",
    "joblib.dump(encoder, model_repo+'encoder.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this file, we will import several models of specific cyber attack classifier (based on DecisionTreeClassifier, best classfier)\n",
    "### We need to import\n",
    "- Classification\n",
    "- All specific attack models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, RidgeClassifier, PassiveAggressiveClassifier, Perceptron, RidgeClassifierCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import joblib\n",
    "import gc\n",
    "\n",
    "# Path to datasets\n",
    "DATASET_DIRECTORY = \".\\Files\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification training (if you already have classification model in your Models repository, you can go to the next section)\n",
    "### Table of content\n",
    "- Importing DataSet\n",
    "- Scaling\n",
    "- Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing DataSet and scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:25<00:00,  3.18s/it]\n"
     ]
    }
   ],
   "source": [
    "# Get all the datasets in the directory and sort them\n",
    "df_sets = [k for k in os.listdir(DATASET_DIRECTORY) if k.endswith('.csv')]\n",
    "df_sets.sort()\n",
    "\n",
    "# Only use a part of all datasets (100 files)\n",
    "df_sets = df_sets[0:10]\n",
    "\n",
    "# Set 80% of the datasets as training sets and 20% as test sets\n",
    "training_sets = df_sets[:int(len(df_sets)*.8)]\n",
    "test_sets = df_sets[int(len(df_sets)*.8):]\n",
    "\n",
    "# Define each column of the dataset and the target column\n",
    "X_columns = [\n",
    "    'flow_duration', 'Header_Length', 'Protocol Type', 'Duration',\n",
    "       'Rate', 'Srate', 'Drate', 'fin_flag_number', 'syn_flag_number',\n",
    "       'rst_flag_number', 'psh_flag_number', 'ack_flag_number',\n",
    "       'ece_flag_number', 'cwr_flag_number', 'ack_count',\n",
    "       'syn_count', 'fin_count', 'urg_count', 'rst_count', \n",
    "    'HTTP', 'HTTPS', 'DNS', 'Telnet', 'SMTP', 'SSH', 'IRC', 'TCP',\n",
    "       'UDP', 'DHCP', 'ARP', 'ICMP', 'IPv', 'LLC', 'Tot sum', 'Min',\n",
    "       'Max', 'AVG', 'Std', 'Tot size', 'IAT', 'Number', 'Magnitue',\n",
    "       'Radius', 'Covariance', 'Variance', 'Weight', \n",
    "]\n",
    "y_column = 'label'\n",
    "\n",
    "# Define the scaler method\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# For each training set\n",
    "for train_set in tqdm(training_sets):\n",
    "    # Fit the scaler on the training sets\n",
    "    scaler.fit(pd.read_csv(DATASET_DIRECTORY + train_set)[X_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [02:38<00:00, 19.78s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:10<00:00,  5.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction results:\n",
      "\n",
      "##### DecisionTreeClassifier (34 classes) #####\n",
      "accuracy_score:  0.9919125295657917\n",
      "recall_score:  0.802321408357807\n",
      "precision_score:  0.7979221157762059\n",
      "f1_score:  0.7966748460187614\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Turn variable to True if you want to save the model\n",
    "save_model = True\n",
    "\n",
    "# Turn variable to True if you want to load the model\n",
    "\n",
    "# Definition of the models to use and their names\n",
    "ML_model = DecisionTreeClassifier()\n",
    "ML_neam = \"DecisionTreeClassifier\"\n",
    "\n",
    "# For each dataset of the training set\n",
    "for train_set in tqdm(training_sets):\n",
    "    # Load the dataset\n",
    "    d = pd.read_csv(DATASET_DIRECTORY + train_set)\n",
    "\n",
    "    # Normalize the dataset\n",
    "    d[X_columns] = scaler.transform(d[X_columns])\n",
    "\n",
    "    # # For each model\n",
    "    # for model in (ML_models):\n",
    "    # Train the model\n",
    "    ML_model.fit(d[X_columns], d[y_column])\n",
    "\n",
    "    # Delete the dataset from the memory\n",
    "    del d\n",
    "\n",
    "# Initialize the list of true labels\n",
    "y_test = []\n",
    "\n",
    "# Initialize the list of predictions\n",
    "preds = []\n",
    "\n",
    "# For each dataset of the test set\n",
    "for test_set in tqdm(test_sets):\n",
    "    # Load the dataset\n",
    "    d_test = pd.read_csv(DATASET_DIRECTORY + test_set)\n",
    "\n",
    "    # Normalize the dataset\n",
    "    d_test[X_columns] = scaler.transform(d_test[X_columns])\n",
    "\n",
    "    # Add the true labels to the list\n",
    "    y_test += list(d_test[y_column].values)\n",
    "    \n",
    "    # For each model\n",
    "    # for i in (range(len(ML_model))):\n",
    "        # Select the model\n",
    "    model = ML_model\n",
    "\n",
    "    # Predict the labels\n",
    "    y_pred = list(model.predict(d_test[X_columns]))\n",
    "\n",
    "    # Add the predictions to the list\n",
    "    preds = preds + y_pred\n",
    "\n",
    "    prediction_result = {\"y_test\":y_test, \"y_pred\":y_pred}\n",
    "\n",
    "    # Delete the dataset from the memory\n",
    "    del d_test\n",
    "\n",
    "# For each prediction\n",
    "print(\"Prediction results:\")\n",
    "print()\n",
    "\n",
    "# If the user wants to save the models\n",
    "if save_model:\n",
    "    # Save the model\n",
    "    joblib.dump(ML_model, f\".\\Models\\model_{ML_neam}_34_classes.pkl\")\n",
    "\n",
    "y_pred = preds\n",
    "#print('y_pred: ', len(y_pred))\n",
    "#print('y_test: ', len(y_test))\n",
    "print(f\"##### {ML_neam} (34 classes) #####\")\n",
    "print('accuracy_score: ', accuracy_score(y_pred, y_test))\n",
    "print('recall_score: ', recall_score(y_pred, y_test, average='macro'))\n",
    "print('precision_score: ', precision_score(y_pred, y_test, average='macro'))\n",
    "print('f1_score: ', f1_score(y_pred, y_test, average='macro'))\n",
    "print()\n",
    "\n",
    "# Flush the memory\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dictionnary for 7 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_7classes = {}\n",
    "dict_7classes['DDoS-RSTFINFlood'] = 'DDoS'\n",
    "dict_7classes['DDoS-PSHACK_Flood'] = 'DDoS'\n",
    "dict_7classes['DDoS-SYN_Flood'] = 'DDoS'\n",
    "dict_7classes['DDoS-UDP_Flood'] = 'DDoS'\n",
    "dict_7classes['DDoS-TCP_Flood'] = 'DDoS'\n",
    "dict_7classes['DDoS-ICMP_Flood'] = 'DDoS'\n",
    "dict_7classes['DDoS-SynonymousIP_Flood'] = 'DDoS'\n",
    "dict_7classes['DDoS-ACK_Fragmentation'] = 'DDoS'\n",
    "dict_7classes['DDoS-UDP_Fragmentation'] = 'DDoS'\n",
    "dict_7classes['DDoS-ICMP_Fragmentation'] = 'DDoS'\n",
    "dict_7classes['DDoS-SlowLoris'] = 'DDoS'\n",
    "dict_7classes['DDoS-HTTP_Flood'] = 'DDoS'\n",
    "\n",
    "dict_7classes['DoS-UDP_Flood'] = 'DoS'\n",
    "dict_7classes['DoS-SYN_Flood'] = 'DoS'\n",
    "dict_7classes['DoS-TCP_Flood'] = 'DoS'\n",
    "dict_7classes['DoS-HTTP_Flood'] = 'DoS'\n",
    "\n",
    "\n",
    "dict_7classes['Mirai-greeth_flood'] = 'Mirai'\n",
    "dict_7classes['Mirai-greip_flood'] = 'Mirai'\n",
    "dict_7classes['Mirai-udpplain'] = 'Mirai'\n",
    "\n",
    "dict_7classes['Recon-PingSweep'] = 'Recon'\n",
    "dict_7classes['Recon-OSScan'] = 'Recon'\n",
    "dict_7classes['Recon-PortScan'] = 'Recon'\n",
    "dict_7classes['VulnerabilityScan'] = 'Recon'\n",
    "dict_7classes['Recon-HostDiscovery'] = 'Recon'\n",
    "\n",
    "dict_7classes['DNS_Spoofing'] = 'Spoofing'\n",
    "dict_7classes['MITM-ArpSpoofing'] = 'Spoofing'\n",
    "\n",
    "dict_7classes['BenignTraffic'] = 'Benign'\n",
    "\n",
    "dict_7classes['BrowserHijacking'] = 'Web'\n",
    "dict_7classes['Backdoor_Malware'] = 'Web'\n",
    "dict_7classes['XSS'] = 'Web'\n",
    "dict_7classes['Uploading_Attack'] = 'Web'\n",
    "dict_7classes['SqlInjection'] = 'Web'\n",
    "dict_7classes['CommandInjection'] = 'Web'\n",
    "\n",
    "\n",
    "dict_7classes['DictionaryBruteForce'] = 'BruteForce'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save of classification prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'model_name': 'DecisionTreeClassifier', 'prediction': 'Mirai-udpplain', 'true_label': 'Mirai-udpplain', 'row_index': 4}, {'model_name': 'DecisionTreeClassifier', 'prediction': 'Mirai-udpplain', 'true_label': 'Mirai-udpplain', 'row_index': 10}, {'model_name': 'DecisionTreeClassifier', 'prediction': 'Mirai-greip_flood', 'true_label': 'Mirai-greip_flood', 'row_index': 19}, {'model_name': 'DecisionTreeClassifier', 'prediction': 'Mirai-greip_flood', 'true_label': 'Mirai-greip_flood', 'row_index': 22}, {'model_name': 'DecisionTreeClassifier', 'prediction': 'Mirai-greeth_flood', 'true_label': 'Mirai-greeth_flood', 'row_index': 44}]\n"
     ]
    }
   ],
   "source": [
    "# Créez un dictionnaire pour stocker les prédictions classées par catégorie\n",
    "classified_predictions = {category: [] for category in dict_7classes.values()}\n",
    "\n",
    "\n",
    "model_name = ML_neam\n",
    "\n",
    "# Itérez sur les prédictions et les lignes correspondantes\n",
    "for index, prediction in enumerate(y_pred):\n",
    "    # Obtenez la catégorie correspondant à la prédiction\n",
    "    category = dict_7classes.get(prediction, None)\n",
    "    \n",
    "    if category:\n",
    "        # Obtenez le vrai label correspondant à l'index actuel depuis y_test\n",
    "        true_label = y_test[index]\n",
    "        \n",
    "        # Ajoutez la prédiction, le modèle, le vrai label et l'index de ligne associés à la catégorie correspondante\n",
    "        classified_predictions[category].append({\n",
    "            'model_name': model_name,\n",
    "            'prediction': prediction,\n",
    "            'true_label': true_label,\n",
    "            'row_index': index\n",
    "        })\n",
    "\n",
    "print(classified_predictions['Mirai'][:5])\n",
    "\n",
    "# # Chargement des modèles spécifiques par catégorie (à adapter selon votre structure de sauvegarde)\n",
    "# def load_models_by_category():\n",
    "#     models_by_category = {}\n",
    "#     for category in dict_7classes.values():\n",
    "#         # Chargez le modèle spécifique à la catégorie depuis le fichier local\n",
    "#         model_filename = f\".\\Models\\model_{category}.pkl\"\n",
    "#         model = joblib.load(model_filename)\n",
    "#         models_by_category[category] = model\n",
    "#     return models_by_category\n",
    "\n",
    "# # Fonction pour prédire une ligne avec le modèle spécifique à la catégorie\n",
    "# def predict_with_category_model(row, category, models_by_category):\n",
    "#     if category in models_by_category:\n",
    "#         model = models_by_category[category]\n",
    "#         # Prédisez la ligne avec le modèle spécifique à la catégorie\n",
    "#         prediction = model.predict([row])  # Assurez-vous que \"row\" est un tableau 2D avec les caractéristiques attendues\n",
    "#         return prediction[0]  # Retournez la prédiction (assumant que le modèle renvoie un tableau de prédictions)\n",
    "#     else:\n",
    "#         return None\n",
    "\n",
    "# # Chargez les modèles spécifiques par catégorie\n",
    "# models_by_category = load_models_by_category()\n",
    "\n",
    "# # Exemple d'utilisation pour prédire une ligne dans une catégorie donnée\n",
    "# row_to_predict = [0.1, 0.2, 0.3, 0.4]  # Remplacez par les caractéristiques de la ligne à prédire\n",
    "# category_to_predict = 'DDoS'  # Remplacez par la catégorie souhaitée\n",
    "# prediction = predict_with_category_model(row_to_predict, category_to_predict, models_by_category)\n",
    "# if prediction is not None:\n",
    "#     print(f\"Prediction for category '{category_to_predict}': {prediction}\")\n",
    "# else:\n",
    "#     print(f\"No model found for category '{category_to_predict}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_data(data, model, X_column, dict_7classes):\n",
    "    # Appliquer les prédictions du modèle aux données\n",
    "    predictions = model.predict(data[X_column])\n",
    "    \n",
    "    # Créer un dictionnaire pour stocker les lignes classées\n",
    "    classified_data = {category: [] for category in dict_7classes.values()}\n",
    "    \n",
    "    # Itérer à travers les données et les prédictions\n",
    "    for index, row in data.iterrows():\n",
    "        prediction = predictions[index]\n",
    "        # Obtenir la catégorie correspondant à la prédiction\n",
    "        category = dict_7classes.get(prediction, None)\n",
    "        if category:\n",
    "            # Ajouter la ligne aux données classées correspondantes\n",
    "            classified_data[category].append(row)\n",
    "    \n",
    "    return classified_data\n",
    "\n",
    "# Utilisation de la fonction pour classer les données\n",
    "classified_data = classify_data(data, model, X_column, dict_7classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2203"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

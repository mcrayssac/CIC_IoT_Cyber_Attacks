{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb6a6862-9ab9-47c7-b5da-0bc772897129",
   "metadata": {},
   "source": [
    "# Training a ML model using CICIoT2023\n",
    "\n",
    "This notebook shows how a LogisticRegression model can be trained using the CICIoT2023 csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40f7c50d-b0ae-4f19-9398-1435ba7a851d",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, RidgeClassifier, PassiveAggressiveClassifier, Perceptron, RidgeClassifierCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c40b5d2-727b-4f37-a480-9d46304eb541",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "DATASET_DIRECTORY = \".\\Files\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3bbe68",
   "metadata": {},
   "source": [
    "XGBoost, LightGBM, CatBoost, Stacking, Baging, Voting\n",
    "Hyperparameter tuning Bayes\n",
    "Importance des caratéristiques\n",
    "Oversampling, undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec1f2b2-92b3-4622-895b-6ac5126f30b4",
   "metadata": {},
   "source": [
    "### Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6854f877-5524-46ba-b7ca-5d6040015f44",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "df_sets = [k for k in os.listdir(DATASET_DIRECTORY) if k.endswith('.csv')]\n",
    "df_sets.sort()\n",
    "# print(df_sets[0:10])\n",
    "\n",
    "# Only use the first 10 datasets\n",
    "# df_sets = df_sets[0:10]\n",
    "\n",
    "training_sets = df_sets[:int(len(df_sets)*.8)]\n",
    "test_sets = df_sets[int(len(df_sets)*.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0433838d-ca57-4dd8-b41c-ad2ee3df61c4",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "X_columns = [\n",
    "    'flow_duration', 'Header_Length', 'Protocol Type', 'Duration',\n",
    "       'Rate', 'Srate', 'Drate', 'fin_flag_number', 'syn_flag_number',\n",
    "       'rst_flag_number', 'psh_flag_number', 'ack_flag_number',\n",
    "       'ece_flag_number', 'cwr_flag_number', 'ack_count',\n",
    "       'syn_count', 'fin_count', 'urg_count', 'rst_count', \n",
    "    'HTTP', 'HTTPS', 'DNS', 'Telnet', 'SMTP', 'SSH', 'IRC', 'TCP',\n",
    "       'UDP', 'DHCP', 'ARP', 'ICMP', 'IPv', 'LLC', 'Tot sum', 'Min',\n",
    "       'Max', 'AVG', 'Std', 'Tot size', 'IAT', 'Number', 'Magnitue',\n",
    "       'Radius', 'Covariance', 'Variance', 'Weight', \n",
    "]\n",
    "y_column = 'label'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249673a6-4826-4b80-b9aa-dfa4c3d549c4",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cba40f31",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3682559f-9eb3-4d35-b1b2-d7d501ab85bc",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 135/135 [01:42<00:00,  1.32it/s]\n"
     ]
    }
   ],
   "source": [
    "for train_set in tqdm(training_sets):\n",
    "    scaler.fit(pd.read_csv(DATASET_DIRECTORY + train_set)[X_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a95c146",
   "metadata": {},
   "source": [
    "## Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "91c9429e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def calculate_false_positives_and_false_negatives_multiclass_auto(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calcule les faux positifs (FP) et les faux négatifs (FN) pour chaque classe dans une classification multiclasse.\n",
    "\n",
    "    Args:\n",
    "    - y_true (array-like): Les vraies étiquettes.\n",
    "    - y_pred (array-like): Les prédictions du modèle.\n",
    "\n",
    "    Returns:\n",
    "    - fp_dict (dict): Un dictionnaire contenant les faux positifs par classe.\n",
    "    - fn_dict (dict): Un dictionnaire contenant les faux négatifs par classe.\n",
    "    - labels (list): La liste des étiquettes uniques de classe.\n",
    "    \"\"\"\n",
    "\n",
    "    labels = np.unique(np.concatenate([y_true, y_pred]))\n",
    "    # Créez un dictionnaire pour mapper les étiquettes aux indices entiers\n",
    "    label_to_index = {label: index for index, label in enumerate(labels)}\n",
    "    \n",
    "    fp_dict = {}\n",
    "    fn_dict = {}\n",
    "    i = 1\n",
    "\n",
    "    for label in tqdm(labels):\n",
    "        # Mapper l'étiquette à l'indice entier\n",
    "        label_index = label_to_index[label]\n",
    "\n",
    "        # Créez une matrice de confusion pour la classe actuelle\n",
    "        cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "        \n",
    "        # Extrayez les valeurs de faux positifs et de faux négatifs pour la classe actuelle\n",
    "        fn = sum(cm[i:, label_index])\n",
    "        temp = cm[label_index, :]\n",
    "        fp = sum(temp[i:])\n",
    "        \n",
    "        fp_dict[label] = fp\n",
    "        fn_dict[label] = fn\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    # Plot the confusion matrix as a heatmap\n",
    "    # cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    # plt.figure(figsize=(25, 18))\n",
    "    # sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', annot_kws={\"size\": 16})\n",
    "    # plt.xlabel('Predicted Labels')\n",
    "    # plt.ylabel('True Labels')\n",
    "    # plt.title('Confusion Matrix')\n",
    "    # plt.show()\n",
    "\n",
    "    data_fp = {\n",
    "        'Category': list(fp_dict.keys()),\n",
    "        'Count': list(fp_dict.values())\n",
    "    }\n",
    "    df_fp = pd.DataFrame(data_fp)\n",
    "    df_fp.sort_values(by=['Count'], inplace=True, ascending=False)\n",
    "\n",
    "    # print(df_fp.head(20))\n",
    "    fp = df_fp['Count'].sum()\n",
    "\n",
    "    data_fn = {\n",
    "        'Category': list(fn_dict.keys()),\n",
    "        'Count': list(fn_dict.values())\n",
    "    }\n",
    "    df_fn = pd.DataFrame(data_fn)\n",
    "    df_fn.sort_values(by=['Count'], inplace=True, ascending=False)\n",
    "\n",
    "    # print(df_fn.head(20))\n",
    "    fn = df_fn['Count'].sum()\n",
    "\n",
    "    return fp, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca942aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:11<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Accuracy': 0.9919064560227088, 'Recall': 0.8140605017853194, 'Precision': 0.7986467333841887, 'F1': 0.8016518586494595, 'FP': 987, 'FN': 949, 'Total': 239203}\n"
     ]
    }
   ],
   "source": [
    "def singlePerformance(model, modelName, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    fp, fn = calculate_false_positives_and_false_negatives_multiclass_auto(y_test, y_pred)\n",
    "\n",
    "    return accuracy_score(y_test, y_pred), recall_score(y_test, y_pred, average='macro'), precision_score(y_test, y_pred, average='macro'), f1_score(y_test, y_pred, average='macro'), fp, fn\n",
    "\n",
    "# Load the model\n",
    "model = joblib.load('.\\\\Models\\\\model_DecisionTreeClassifier_34_classes.joblib')\n",
    "\n",
    "# Load the test set\n",
    "X_test = pd.read_csv(DATASET_DIRECTORY + test_sets[0])[X_columns]\n",
    "y_test = pd.read_csv(DATASET_DIRECTORY + test_sets[0])[y_column]\n",
    "# print(X_test[:5])\n",
    "# print(y_test[:5])\n",
    "# print(len(y_test))\n",
    "\n",
    "# Scale the test set\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Get the performance\n",
    "accuracy, recall, precision, f1, fp, fn = singlePerformance(model, 'DecisionTreeClassifier', X_test, y_test)\n",
    "performance = {'Accuracy': accuracy, 'Recall': recall, 'Precision': precision, 'F1': f1, 'FP': fp, 'FN': fn, 'Total': len(y_test)}\n",
    "print(performance)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60abc3f0-e32d-40be-abc5-fd5972cf9856",
   "metadata": {},
   "source": [
    "# Classification: 34 (33+1) classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d208cf46-8ba9-480f-ab99-d4ee81c083b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/135 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    DDoS-RSTFINFlood\n",
      "1       DoS-TCP_Flood\n",
      "2     DDoS-ICMP_Flood\n",
      "3       DoS-UDP_Flood\n",
      "4       DoS-SYN_Flood\n",
      "Name: label, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/135 [00:08<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mlcra\\Desktop\\S5-Alt-2\\Données Massives\\CIC_IoT_Cyber_Attacks\\example.ipynb Cell 15\u001b[0m line \u001b[0;36m<cell line: 16>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mlcra/Desktop/S5-Alt-2/Donn%C3%A9es%20Massives/CIC_IoT_Cyber_Attacks/example.ipynb#X13sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m# Pour chaque modèle\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mlcra/Desktop/S5-Alt-2/Donn%C3%A9es%20Massives/CIC_IoT_Cyber_Attacks/example.ipynb#X13sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m (ML_models):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mlcra/Desktop/S5-Alt-2/Donn%C3%A9es%20Massives/CIC_IoT_Cyber_Attacks/example.ipynb#X13sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mlcra/Desktop/S5-Alt-2/Donn%C3%A9es%20Massives/CIC_IoT_Cyber_Attacks/example.ipynb#X13sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39m# On entraîne le modèle\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mlcra/Desktop/S5-Alt-2/Donn%C3%A9es%20Massives/CIC_IoT_Cyber_Attacks/example.ipynb#X13sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     model\u001b[39m.\u001b[39;49mfit(d[X_columns], d[y_column])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mlcra/Desktop/S5-Alt-2/Donn%C3%A9es%20Massives/CIC_IoT_Cyber_Attacks/example.ipynb#X13sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# On supprime le dataset\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mlcra/Desktop/S5-Alt-2/Donn%C3%A9es%20Massives/CIC_IoT_Cyber_Attacks/example.ipynb#X13sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mdel\u001b[39;00m d\n",
      "File \u001b[1;32mc:\\Users\\mlcra\\AppData\\Local\\Programs\\Orange\\lib\\site-packages\\sklearn\\tree\\_classes.py:969\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    939\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    940\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    941\u001b[0m \n\u001b[0;32m    942\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    966\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    967\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 969\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    970\u001b[0m         X,\n\u001b[0;32m    971\u001b[0m         y,\n\u001b[0;32m    972\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    973\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m    974\u001b[0m     )\n\u001b[0;32m    975\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\mlcra\\AppData\\Local\\Programs\\Orange\\lib\\site-packages\\sklearn\\tree\\_classes.py:458\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    448\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    449\u001b[0m         splitter,\n\u001b[0;32m    450\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    455\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    456\u001b[0m     )\n\u001b[1;32m--> 458\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[0;32m    460\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[0;32m    461\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ML_models = [\n",
    "        DecisionTreeClassifier(),\n",
    "        RandomForestClassifier(n_jobs=-1),\n",
    "        # GradientBoostingClassifier(),\n",
    "        # LogisticRegression(n_jobs=-1),\n",
    "]\n",
    "\n",
    "ML_neams = [\n",
    "        \"DecisionTreeClassifier\",\n",
    "        \"RandomForestClassifier\",\n",
    "        # \"GradientBoostingClassifier\",\n",
    "        # \"LogisticRegression\",\n",
    "]\n",
    "\n",
    "# Pour chaque dataset\n",
    "for train_set in tqdm(training_sets):\n",
    "    \n",
    "    # On charge le dataset\n",
    "    d = pd.read_csv(DATASET_DIRECTORY + train_set)\n",
    "\n",
    "    # On normalise les données\n",
    "    d[X_columns] = scaler.transform(d[X_columns])\n",
    "\n",
    "    print(d[y_column].head())\n",
    "\n",
    "    # Pour chaque modèle\n",
    "    for model in (ML_models):\n",
    "\n",
    "        # On entraîne le modèle\n",
    "        model.fit(d[X_columns], d[y_column])\n",
    "\n",
    "    # On supprime le dataset\n",
    "    del d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6116132e-02f0-4bac-aefb-2ba0bee924ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:12<00:00,  6.17s/it]\n"
     ]
    }
   ],
   "source": [
    "y_test = []\n",
    "preds = {i:[] for i in range(len(ML_models))}\n",
    "for test_set in tqdm(test_sets):\n",
    "    d_test = pd.read_csv(DATASET_DIRECTORY + test_set)\n",
    "    d_test[X_columns] = scaler.transform(d_test[X_columns])\n",
    "    \n",
    "    y_test += list(d_test[y_column].values)\n",
    "    \n",
    "    for i in range(len(ML_models)):\n",
    "        model = ML_models[i]\n",
    "        y_pred = list(model.predict(d_test[X_columns]))\n",
    "        preds[i] = preds[i] + y_pred\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "375dcbfb-2b20-4b37-8fbb-c9d68a6ac541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### DecisionTreeClassifier (34 classes) #####\n",
      "accuracy_score:  0.9919694984417957\n",
      "recall_score:  0.8285072816643488\n",
      "precision_score:  0.8174407816479924\n",
      "f1_score:  0.8185581953657711\n",
      "\n",
      "\n",
      "\n",
      "##### RandomForestClassifier (34 classes) #####\n",
      "accuracy_score:  0.9917859320635604\n",
      "recall_score:  0.7562229609843071\n",
      "precision_score:  0.7041411955073251\n",
      "f1_score:  0.7074143686576185\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "for k,v in preds.items():\n",
    "    y_pred = v\n",
    "    print(f\"##### {ML_neams[k]} (34 classes) #####\")\n",
    "    print('accuracy_score: ', accuracy_score(y_pred, y_test))\n",
    "    print('recall_score: ', recall_score(y_pred, y_test, average='macro'))\n",
    "    print('precision_score: ', precision_score(y_pred, y_test, average='macro'))\n",
    "    print('f1_score: ', f1_score(y_pred, y_test, average='macro'))\n",
    "    print()\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f643a8",
   "metadata": {},
   "source": [
    "# Results for classification 34 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb6fe0a",
   "metadata": {},
   "source": [
    "##### LogisticRegression (34 classes) #####\n",
    "- accuracy_score:  0.8016639131709932\n",
    "- recall_score:  0.5854951774651348\n",
    "- precision_score:  0.48305324146988726\n",
    "- f1_score:  0.48966648273998686\n",
    "\n",
    "##### DecisionTreeClassifier (34 classes) #####\n",
    "- accuracy_score:  0.9920159175259472\n",
    "- recall_score:  0.8244818441920118\n",
    "- precision_score:  0.8205782334865411\n",
    "- f1_score:  0.8200383982988425\n",
    "\n",
    "##### RandomForestClassifier (34 classes) #####\n",
    "- accuracy_score:  0.9915897059351019\n",
    "- recall_score:  0.7620503146664692\n",
    "- precision_score:  0.7011582842714431\n",
    "- f1_score:  0.7057468323931881\n",
    "\n",
    "##### GradientBoostingClassifier (34 classes) #####\n",
    "- accuracy_score:  0.9888108907611253\n",
    "- recall_score:  0.7582318098632861\n",
    "- precision_score:  0.7223169808416247\n",
    "- f1_score:  0.7231863656996314\n",
    "\n",
    "##### AdaBoostClassifier (34 classes) #####\n",
    "- accuracy_score:  0.4407196646010174\n",
    "- recall_score:  0.41902247243947177\n",
    "- precision_score:  0.3750765477184141\n",
    "- f1_score:  0.3265605952381953\n",
    "\n",
    "##### SGDClassifier (34 classes) #####\n",
    "- accuracy_score:  0.7886454700248764\n",
    "- recall_score:  0.5132378715903361\n",
    "- precision_score:  0.42617099932129565\n",
    "- f1_score:  0.4299622886448148\n",
    "\n",
    "##### RidgeClassifier (34 classes) #####\n",
    "- accuracy_score:  0.7631740525759427\n",
    "- recall_score:  0.43010389536148935\n",
    "- precision_score:  0.349978545679562\n",
    "- f1_score:  0.32991209467439137\n",
    "\n",
    "##### PassiveAggressiveClassifier (34 classes) #####\n",
    "- accuracy_score:  0.7758717820497402\n",
    "- recall_score:  0.509216893964416\n",
    "- precision_score:  0.4269679598736629\n",
    "- f1_score:  0.4331352936302771\n",
    "\n",
    "##### Perceptron (34 classes) #####\n",
    "- accuracy_score:  0.7359091705120658\n",
    "- recall_score:  0.49828519884605005\n",
    "- precision_score:  0.4407204631508492\n",
    "- f1_score:  0.42571768601861915\n",
    "\n",
    "##### RidgeClassifierCV (34 classes) #####\n",
    "- accuracy_score:  0.7631360733252733\n",
    "- recall_score:  0.4300375882496944\n",
    "- precision_score:  0.34992014844272346\n",
    "- f1_score:  0.32990912274049855"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3958c6fa-6d05-48fb-a046-55e5843e4711",
   "metadata": {},
   "source": [
    "# Classification: 8 (7+1) classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9208c899-8b57-4a3a-a2e7-94b057123536",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_7classes = {}\n",
    "dict_7classes['DDoS-RSTFINFlood'] = 'DDoS'\n",
    "dict_7classes['DDoS-PSHACK_Flood'] = 'DDoS'\n",
    "dict_7classes['DDoS-SYN_Flood'] = 'DDoS'\n",
    "dict_7classes['DDoS-UDP_Flood'] = 'DDoS'\n",
    "dict_7classes['DDoS-TCP_Flood'] = 'DDoS'\n",
    "dict_7classes['DDoS-ICMP_Flood'] = 'DDoS'\n",
    "dict_7classes['DDoS-SynonymousIP_Flood'] = 'DDoS'\n",
    "dict_7classes['DDoS-ACK_Fragmentation'] = 'DDoS'\n",
    "dict_7classes['DDoS-UDP_Fragmentation'] = 'DDoS'\n",
    "dict_7classes['DDoS-ICMP_Fragmentation'] = 'DDoS'\n",
    "dict_7classes['DDoS-SlowLoris'] = 'DDoS'\n",
    "dict_7classes['DDoS-HTTP_Flood'] = 'DDoS'\n",
    "\n",
    "dict_7classes['DoS-UDP_Flood'] = 'DoS'\n",
    "dict_7classes['DoS-SYN_Flood'] = 'DoS'\n",
    "dict_7classes['DoS-TCP_Flood'] = 'DoS'\n",
    "dict_7classes['DoS-HTTP_Flood'] = 'DoS'\n",
    "\n",
    "\n",
    "dict_7classes['Mirai-greeth_flood'] = 'Mirai'\n",
    "dict_7classes['Mirai-greip_flood'] = 'Mirai'\n",
    "dict_7classes['Mirai-udpplain'] = 'Mirai'\n",
    "\n",
    "dict_7classes['Recon-PingSweep'] = 'Recon'\n",
    "dict_7classes['Recon-OSScan'] = 'Recon'\n",
    "dict_7classes['Recon-PortScan'] = 'Recon'\n",
    "dict_7classes['VulnerabilityScan'] = 'Recon'\n",
    "dict_7classes['Recon-HostDiscovery'] = 'Recon'\n",
    "\n",
    "dict_7classes['DNS_Spoofing'] = 'Spoofing'\n",
    "dict_7classes['MITM-ArpSpoofing'] = 'Spoofing'\n",
    "\n",
    "dict_7classes['BenignTraffic'] = 'Benign'\n",
    "\n",
    "dict_7classes['BrowserHijacking'] = 'Web'\n",
    "dict_7classes['Backdoor_Malware'] = 'Web'\n",
    "dict_7classes['XSS'] = 'Web'\n",
    "dict_7classes['Uploading_Attack'] = 'Web'\n",
    "dict_7classes['SqlInjection'] = 'Web'\n",
    "dict_7classes['CommandInjection'] = 'Web'\n",
    "\n",
    "\n",
    "dict_7classes['DictionaryBruteForce'] = 'BruteForce'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4c1f697f-88d8-4ac4-8bc6-f1a8ac3794d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [1:06:06<00:00, 495.85s/it]\n"
     ]
    }
   ],
   "source": [
    "ML_models = [\n",
    "        # DecisionTreeClassifier(),\n",
    "        RandomForestClassifier(n_jobs=-1),\n",
    "        GradientBoostingClassifier(),\n",
    "        # LogisticRegression(n_jobs=-1),\n",
    "]\n",
    "\n",
    "ML_neams = [\n",
    "        # \"DecisionTreeClassifier\",\n",
    "        \"RandomForestClassifier\",\n",
    "        \"GradientBoostingClassifier\",\n",
    "        # \"LogisticRegression\",\n",
    "]\n",
    "\n",
    "\n",
    "for train_set in tqdm(training_sets):\n",
    "    d = pd.read_csv(DATASET_DIRECTORY + train_set)\n",
    "    d[X_columns] = scaler.transform(d[X_columns])\n",
    "    new_y = [dict_7classes[k] for k in d[y_column]]\n",
    "    d[y_column] = new_y\n",
    "    \n",
    "    for model in (ML_models):\n",
    "        model.fit(d[X_columns], d[y_column])\n",
    "    del d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "6b69c509-7666-45bd-9e11-52ecec0df8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:13<00:00,  6.85s/it]\n"
     ]
    }
   ],
   "source": [
    "y_test = []\n",
    "preds = {i:[] for i in range(len(ML_models))}\n",
    "for test_set in tqdm(test_sets):\n",
    "    d_test = pd.read_csv(DATASET_DIRECTORY + test_set)\n",
    "    d_test[X_columns] = scaler.transform(d_test[X_columns])\n",
    "    new_y = [dict_7classes[k] for k in d_test[y_column]]\n",
    "    d_test[y_column] = new_y\n",
    "    \n",
    "    y_test += list(d_test[y_column].values)\n",
    "    \n",
    "    for i in range(len(ML_models)):\n",
    "        model = ML_models[i]\n",
    "        y_pred = list(model.predict(d_test[X_columns]))\n",
    "        preds[i] = preds[i] + y_pred\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3e0a9702-63f5-4898-a8b0-2bf950fe881d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### RandomForestClassifier (8 classes) #####\n",
      "accuracy_score =  0.9944550294022699\n",
      "recall_score =  0.8728695527711083\n",
      "precision_score =  0.7056110449239469\n",
      "f1_score =  0.7180407251186967\n",
      "\n",
      "\n",
      "\n",
      "##### GradientBoostingClassifier (8 classes) #####\n",
      "accuracy_score =  0.9946554754474695\n",
      "recall_score =  0.9040814776453021\n",
      "precision_score =  0.818092568562414\n",
      "f1_score =  0.8473350976774587\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "for k,v in preds.items():\n",
    "    y_pred = v\n",
    "    print(f\"##### {ML_neams[k]} (8 classes) #####\")\n",
    "    print('accuracy_score = ', accuracy_score(y_pred, y_test))\n",
    "    print('recall_score = ', recall_score(y_pred, y_test, average='macro'))\n",
    "    print('precision_score = ', precision_score(y_pred, y_test, average='macro'))\n",
    "    print('f1_score = ', f1_score(y_pred, y_test, average='macro'))\n",
    "    print()\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b31b38",
   "metadata": {},
   "source": [
    "# Results for classification 8 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f80f48a",
   "metadata": {},
   "source": [
    "##### DecisionTreeClassifier (8 classes) #####\n",
    "- accuracy_score =  0.9939887286023846\n",
    "- recall_score =  0.8211775275457525\n",
    "- precision_score =  0.8234005860868705\n",
    "- f1_score =  0.8222522645707806\n",
    "\n",
    "##### RandomForestClassifier (8 classes) #####\n",
    "- accuracy_score =  0.9944339298185647\n",
    "- recall_score =  0.9009198371610123\n",
    "- precision_score =  0.701561593137628\n",
    "- f1_score =  0.7103702473263263\n",
    "\n",
    "##### GradientBoostingClassifier (8 classes) #####\n",
    "- accuracy_score =  0.9946639152809515\n",
    "- recall_score =  0.9051566339711138\n",
    "- precision_score =  0.8182008967354992\n",
    "- f1_score =  0.8478305023003074\n",
    "\n",
    "##### LogisticRegression (8 classes) #####\n",
    "- accuracy_score =  0.8314523054460136\n",
    "- recall_score =  0.8285613319370242\n",
    "- precision_score =  0.5139777696307017\n",
    "- f1_score =  0.540448857067295"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ecac59-fc02-4198-9910-daf890da7a0a",
   "metadata": {},
   "source": [
    "# Classification: 2 (1+1) Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "90ee4a99-d160-43bc-b2a0-06fa3f49e222",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_2classes = {}\n",
    "dict_2classes['DDoS-RSTFINFlood'] = 'Attack'\n",
    "dict_2classes['DDoS-PSHACK_Flood'] = 'Attack'\n",
    "dict_2classes['DDoS-SYN_Flood'] = 'Attack'\n",
    "dict_2classes['DDoS-UDP_Flood'] = 'Attack'\n",
    "dict_2classes['DDoS-TCP_Flood'] = 'Attack'\n",
    "dict_2classes['DDoS-ICMP_Flood'] = 'Attack'\n",
    "dict_2classes['DDoS-SynonymousIP_Flood'] = 'Attack'\n",
    "dict_2classes['DDoS-ACK_Fragmentation'] = 'Attack'\n",
    "dict_2classes['DDoS-UDP_Fragmentation'] = 'Attack'\n",
    "dict_2classes['DDoS-ICMP_Fragmentation'] = 'Attack'\n",
    "dict_2classes['DDoS-SlowLoris'] = 'Attack'\n",
    "dict_2classes['DDoS-HTTP_Flood'] = 'Attack'\n",
    "\n",
    "dict_2classes['DoS-UDP_Flood'] = 'Attack'\n",
    "dict_2classes['DoS-SYN_Flood'] = 'Attack'\n",
    "dict_2classes['DoS-TCP_Flood'] = 'Attack'\n",
    "dict_2classes['DoS-HTTP_Flood'] = 'Attack'\n",
    "\n",
    "\n",
    "dict_2classes['Mirai-greeth_flood'] = 'Attack'\n",
    "dict_2classes['Mirai-greip_flood'] = 'Attack'\n",
    "dict_2classes['Mirai-udpplain'] = 'Attack'\n",
    "\n",
    "dict_2classes['Recon-PingSweep'] = 'Attack'\n",
    "dict_2classes['Recon-OSScan'] = 'Attack'\n",
    "dict_2classes['Recon-PortScan'] = 'Attack'\n",
    "dict_2classes['VulnerabilityScan'] = 'Attack'\n",
    "dict_2classes['Recon-HostDiscovery'] = 'Attack'\n",
    "\n",
    "dict_2classes['DNS_Spoofing'] = 'Attack'\n",
    "dict_2classes['MITM-ArpSpoofing'] = 'Attack'\n",
    "\n",
    "dict_2classes['BenignTraffic'] = 'Benign'\n",
    "\n",
    "dict_2classes['BrowserHijacking'] = 'Attack'\n",
    "dict_2classes['Backdoor_Malware'] = 'Attack'\n",
    "dict_2classes['XSS'] = 'Attack'\n",
    "dict_2classes['Uploading_Attack'] = 'Attack'\n",
    "dict_2classes['SqlInjection'] = 'Attack'\n",
    "dict_2classes['CommandInjection'] = 'Attack'\n",
    "\n",
    "dict_2classes['DictionaryBruteForce'] = 'Attack'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "506eae35-a310-4a34-8bcf-c99282ed3225",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [08:31<00:00, 63.88s/it]\n"
     ]
    }
   ],
   "source": [
    "ML_models = [\n",
    "        # DecisionTreeClassifier(),\n",
    "        RandomForestClassifier(n_jobs=-1),\n",
    "        GradientBoostingClassifier(),\n",
    "        # LogisticRegression(n_jobs=-1),\n",
    "]\n",
    "\n",
    "ML_neams = [\n",
    "        # \"DecisionTreeClassifier\",\n",
    "        \"RandomForestClassifier\",\n",
    "        \"GradientBoostingClassifier\",\n",
    "        # \"LogisticRegression\",\n",
    "]\n",
    "\n",
    "\n",
    "for train_set in tqdm(training_sets):\n",
    "    d = pd.read_csv(DATASET_DIRECTORY + train_set)\n",
    "    d[X_columns] = scaler.transform(d[X_columns])\n",
    "    new_y = [dict_2classes[k] for k in d[y_column]]\n",
    "    d[y_column] = new_y\n",
    "    \n",
    "    for model in (ML_models):\n",
    "        model.fit(d[X_columns], d[y_column])\n",
    "    del d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b07aa379-ec7e-4651-ab5a-6845ae249132",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:04<00:00,  2.20s/it]\n"
     ]
    }
   ],
   "source": [
    "y_test = []\n",
    "preds = {i:[] for i in range(len(ML_models))}\n",
    "for test_set in tqdm(test_sets):\n",
    "    d_test = pd.read_csv(DATASET_DIRECTORY + test_set)\n",
    "    d_test[X_columns] = scaler.transform(d_test[X_columns])\n",
    "    new_y = [dict_2classes[k] for k in d_test[y_column]]\n",
    "    d_test[y_column] = new_y\n",
    "    \n",
    "    y_test += list(d_test[y_column].values)\n",
    "    \n",
    "    for i in range(len(ML_models)):\n",
    "        model = ML_models[i]\n",
    "        y_pred = list(model.predict(d_test[X_columns]))\n",
    "        preds[i] = preds[i] + y_pred\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "caabf4fd-097d-4db2-847a-0dcd87144d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### GradientBoostingClassifier (2 classes) #####\n",
      "accuracy_score:  0.9963455521022571\n",
      "recall_score:  0.9564042322752894\n",
      "precision_score:  0.9662941895334612\n",
      "f1_score:  0.9612933295489201\n",
      "\n",
      "\n",
      "\n",
      "##### LogisticRegression (2 classes) #####\n",
      "accuracy_score:  0.9888741895122409\n",
      "recall_score:  0.8922684294547429\n",
      "precision_score:  0.8609859484895439\n",
      "f1_score:  0.8759404050008108\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "for k,v in preds.items():\n",
    "    y_pred = v\n",
    "    print(f\"##### {ML_neams[k]} (2 classes) #####\")\n",
    "    print('accuracy_score: ', accuracy_score(y_pred, y_test))\n",
    "    print('recall_score: ', recall_score(y_pred, y_test, average='macro'))\n",
    "    print('precision_score: ', precision_score(y_pred, y_test, average='macro'))\n",
    "    print('f1_score: ', f1_score(y_pred, y_test, average='macro'))\n",
    "    print()\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a261309",
   "metadata": {},
   "source": [
    "# Results for classification 2 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94e9aa6",
   "metadata": {},
   "source": [
    "##### DecisionTreeClassifier (2 classes) #####\n",
    "- accuracy_score:  0.995653485756726\n",
    "- recall_score:  0.9543082158556345\n",
    "- precision_score:  0.9524318184616076\n",
    "- f1_score:  0.9533679707468838\n",
    "\n",
    "##### RandomForestClassifier (2 classes) #####\n",
    "- accuracy_score:  0.9968013031102896\n",
    "- recall_score:  0.9654937646506515\n",
    "- precision_score:  0.9660544448649474\n",
    "- f1_score:  0.9657739270096768\n",
    "\n",
    "##### GradientBoostingClassifier (2 classes) #####\n",
    "- accuracy_score:  0.9963455521022571\n",
    "- recall_score:  0.9564042322752894\n",
    "- precision_score:  0.9662941895334612\n",
    "- f1_score:  0.9612933295489201\n",
    "\n",
    "##### LogisticRegression (2 classes) #####\n",
    "- accuracy_score:  0.9888741895122409\n",
    "- recall_score:  0.8922684294547429\n",
    "- precision_score:  0.8609859484895439\n",
    "- f1_score:  0.8759404050008108"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e96d1a",
   "metadata": {},
   "source": [
    "# Specific attack model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b688ce7f",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dict_2classes': {'DDoS-RSTFINFlood': 'DDoS', 'DDoS-PSHACK_Flood': 'DDoS', 'DDoS-SYN_Flood': 'DDoS', 'DDoS-UDP_Flood': 'DDoS', 'DDoS-TCP_Flood': 'DDoS', 'DDoS-ICMP_Flood': 'DDoS', 'DDoS-SynonymousIP_Flood': 'DDoS', 'DDoS-ACK_Fragmentation': 'DDoS', 'DDoS-UDP_Fragmentation': 'DDoS', 'DDoS-ICMP_Fragmentation': 'DDoS', 'DDoS-SlowLoris': 'DDoS', 'DDoS-HTTP_Flood': 'DDoS', 'DoS-UDP_Flood': 'Non-DDoS', 'DoS-SYN_Flood': 'Non-DDoS', 'DoS-TCP_Flood': 'Non-DDoS', 'DoS-HTTP_Flood': 'Non-DDoS', 'Mirai-greeth_flood': 'Non-DDoS', 'Mirai-greip_flood': 'Non-DDoS', 'Mirai-udpplain': 'Non-DDoS', 'Recon-PingSweep': 'Non-DDoS', 'Recon-OSScan': 'Non-DDoS', 'Recon-PortScan': 'Non-DDoS', 'VulnerabilityScan': 'Non-DDoS', 'Recon-HostDiscovery': 'Non-DDoS', 'DNS_Spoofing': 'Non-DDoS', 'MITM-ArpSpoofing': 'Non-DDoS', 'BenignTraffic': 'Non-DDoS', 'BrowserHijacking': 'Non-DDoS', 'Backdoor_Malware': 'Non-DDoS', 'XSS': 'Non-DDoS', 'Uploading_Attack': 'Non-DDoS', 'SqlInjection': 'Non-DDoS', 'CommandInjection': 'Non-DDoS', 'DictionaryBruteForce': 'Non-DDoS'}, 'type': 'DDoS'}\n"
     ]
    }
   ],
   "source": [
    "# Define the 2 classes for each attack type to create a specific model for each attack type\n",
    "# DDoS :\n",
    "dict_2classes_DDoS = {'DDoS-RSTFINFlood': 'DDoS', 'DDoS-PSHACK_Flood': 'DDoS', 'DDoS-SYN_Flood': 'DDoS', 'DDoS-UDP_Flood': 'DDoS', 'DDoS-TCP_Flood': 'DDoS', 'DDoS-ICMP_Flood': 'DDoS', 'DDoS-SynonymousIP_Flood': 'DDoS', 'DDoS-ACK_Fragmentation': 'DDoS', 'DDoS-UDP_Fragmentation': 'DDoS', 'DDoS-ICMP_Fragmentation': 'DDoS', 'DDoS-SlowLoris': 'DDoS', 'DDoS-HTTP_Flood': 'DDoS',\n",
    "                      'DoS-UDP_Flood': 'Non-DDoS', 'DoS-SYN_Flood': 'Non-DDoS', 'DoS-TCP_Flood': 'Non-DDoS', 'DoS-HTTP_Flood': 'Non-DDoS', \n",
    "                      'Mirai-greeth_flood': 'Non-DDoS', 'Mirai-greip_flood': 'Non-DDoS', 'Mirai-udpplain': 'Non-DDoS', \n",
    "                      'Recon-PingSweep': 'Non-DDoS', 'Recon-OSScan': 'Non-DDoS', 'Recon-PortScan': 'Non-DDoS', 'VulnerabilityScan': 'Non-DDoS', 'Recon-HostDiscovery': 'Non-DDoS', \n",
    "                      'DNS_Spoofing': 'Non-DDoS', 'MITM-ArpSpoofing': 'Non-DDoS', \n",
    "                      'BenignTraffic': 'Non-DDoS', \n",
    "                      'BrowserHijacking': 'Non-DDoS', 'Backdoor_Malware': 'Non-DDoS', 'XSS': 'Non-DDoS', 'Uploading_Attack': 'Non-DDoS', 'SqlInjection': 'Non-DDoS', 'CommandInjection': 'Non-DDoS', \n",
    "                      'DictionaryBruteForce': 'Non-DDoS'}\n",
    "\n",
    "# DoS :\n",
    "dict_2classes_DoS = {'DDoS-RSTFINFlood': 'Non-DoS', 'DDoS-PSHACK_Flood': 'Non-DoS', 'DDoS-SYN_Flood': 'Non-DoS', 'DDoS-UDP_Flood': 'Non-DoS', 'DDoS-TCP_Flood': 'Non-DoS', 'DDoS-ICMP_Flood': 'Non-DoS', 'DDoS-SynonymousIP_Flood': 'Non-DoS', 'DDoS-ACK_Fragmentation': 'Non-DoS', 'DDoS-UDP_Fragmentation': 'Non-DoS', 'DDoS-ICMP_Fragmentation': 'Non-DoS', 'DDoS-SlowLoris': 'Non-DoS', 'DDoS-HTTP_Flood': 'Non-DoS',\n",
    "                      'DoS-UDP_Flood': 'DoS', 'DoS-SYN_Flood': 'DoS', 'DoS-TCP_Flood': 'DoS', 'DoS-HTTP_Flood': 'DoS', \n",
    "                      'Mirai-greeth_flood': 'Non-DoS', 'Mirai-greip_flood': 'Non-DoS', 'Mirai-udpplain': 'Non-DoS', \n",
    "                      'Recon-PingSweep': 'Non-DoS', 'Recon-OSScan': 'Non-DoS', 'Recon-PortScan': 'Non-DoS', 'VulnerabilityScan': 'Non-DoS', 'Recon-HostDiscovery': 'Non-DoS', \n",
    "                      'DNS_Spoofing': 'Non-DoS', 'MITM-ArpSpoofing': 'Non-DoS', \n",
    "                      'BenignTraffic': 'Non-DoS', \n",
    "                      'BrowserHijacking': 'Non-DoS', 'Backdoor_Malware': 'Non-DoS', 'XSS': 'Non-DoS', 'Uploading_Attack': 'Non-DoS', 'SqlInjection': 'Non-DoS', 'CommandInjection': 'Non-DoS', \n",
    "                      'DictionaryBruteForce': 'Non-DoS'}\n",
    "\n",
    "# Mirai :\n",
    "dict_2classes_Mirai = {'DDoS-RSTFINFlood': 'Non-Mirai', 'DDoS-PSHACK_Flood': 'Non-Mirai', 'DDoS-SYN_Flood': 'Non-Mirai', 'DDoS-UDP_Flood': 'Non-Mirai', 'DDoS-TCP_Flood': 'Non-Mirai', 'DDoS-ICMP_Flood': 'Non-Mirai', 'DDoS-SynonymousIP_Flood': 'Non-Mirai', 'DDoS-ACK_Fragmentation': 'Non-Mirai', 'DDoS-UDP_Fragmentation': 'Non-Mirai', 'DDoS-ICMP_Fragmentation': 'Non-Mirai', 'DDoS-SlowLoris': 'Non-Mirai', 'DDoS-HTTP_Flood': 'Non-Mirai',\n",
    "                      'DoS-UDP_Flood': 'Non-Mirai', 'DoS-SYN_Flood': 'Non-Mirai', 'DoS-TCP_Flood': 'Non-Mirai', 'DoS-HTTP_Flood': 'Non-Mirai', \n",
    "                      'Mirai-greeth_flood': 'Mirai', 'Mirai-greip_flood': 'Mirai', 'Mirai-udpplain': 'Mirai', \n",
    "                      'Recon-PingSweep': 'Non-Mirai', 'Recon-OSScan': 'Non-Mirai', 'Recon-PortScan': 'Non-Mirai', 'VulnerabilityScan': 'Non-Mirai', 'Recon-HostDiscovery': 'Non-Mirai', \n",
    "                      'DNS_Spoofing': 'Non-Mirai', 'MITM-ArpSpoofing': 'Non-Mirai', \n",
    "                      'BenignTraffic': 'Non-Mirai', \n",
    "                      'BrowserHijacking': 'Non-Mirai', 'Backdoor_Malware': 'Non-Mirai', 'XSS': 'Non-Mirai', 'Uploading_Attack': 'Non-Mirai', 'SqlInjection': 'Non-Mirai', 'CommandInjection': 'Non-Mirai', \n",
    "                      'DictionaryBruteForce': 'Non-Mirai'}\n",
    "\n",
    "# Recon :\n",
    "dict_2classes_Recon = {'DDoS-RSTFINFlood': 'Non-Recon', 'DDoS-PSHACK_Flood': 'Non-Recon', 'DDoS-SYN_Flood': 'Non-Recon', 'DDoS-UDP_Flood': 'Non-Recon', 'DDoS-TCP_Flood': 'Non-Recon', 'DDoS-ICMP_Flood': 'Non-Recon', 'DDoS-SynonymousIP_Flood': 'Non-Recon', 'DDoS-ACK_Fragmentation': 'Non-Recon', 'DDoS-UDP_Fragmentation': 'Non-Recon', 'DDoS-ICMP_Fragmentation': 'Non-Recon', 'DDoS-SlowLoris': 'Non-Recon', 'DDoS-HTTP_Flood': 'Non-Recon',\n",
    "                      'DoS-UDP_Flood': 'Non-Recon', 'DoS-SYN_Flood': 'Non-Recon', 'DoS-TCP_Flood': 'Non-Recon', 'DoS-HTTP_Flood': 'Non-Recon', \n",
    "                      'Mirai-greeth_flood': 'Non-Recon', 'Mirai-greip_flood': 'Non-Recon', 'Mirai-udpplain': 'Non-Recon', \n",
    "                      'Recon-PingSweep': 'Recon', 'Recon-OSScan': 'Recon', 'Recon-PortScan': 'Recon', 'VulnerabilityScan': 'Recon', 'Recon-HostDiscovery': 'Recon', \n",
    "                      'DNS_Spoofing': 'Non-Recon', 'MITM-ArpSpoofing': 'Non-Recon', \n",
    "                      'BenignTraffic': 'Non-Recon', \n",
    "                      'BrowserHijacking': 'Non-Recon', 'Backdoor_Malware': 'Non-Recon', 'XSS': 'Non-Recon', 'Uploading_Attack': 'Non-Recon', 'SqlInjection': 'Non-Recon', 'CommandInjection': 'Non-Recon', \n",
    "                      'DictionaryBruteForce': 'Non-Recon'}\n",
    "\n",
    "# Spoofing :\n",
    "dict_2classes_Spoofing = {'DDoS-RSTFINFlood': 'Non-Spoofing', 'DDoS-PSHACK_Flood': 'Non-Spoofing', 'DDoS-SYN_Flood': 'Non-Spoofing', 'DDoS-UDP_Flood': 'Non-Spoofing', 'DDoS-TCP_Flood': 'Non-Spoofing', 'DDoS-ICMP_Flood': 'Non-Spoofing', 'DDoS-SynonymousIP_Flood': 'Non-Spoofing', 'DDoS-ACK_Fragmentation': 'Non-Spoofing', 'DDoS-UDP_Fragmentation': 'Non-Spoofing', 'DDoS-ICMP_Fragmentation': 'Non-Spoofing', 'DDoS-SlowLoris': 'Non-Spoofing', 'DDoS-HTTP_Flood': 'Non-Spoofing',\n",
    "                      'DoS-UDP_Flood': 'Non-Spoofing', 'DoS-SYN_Flood': 'Non-Spoofing', 'DoS-TCP_Flood': 'Non-Spoofing', 'DoS-HTTP_Flood': 'Non-Spoofing', \n",
    "                      'Mirai-greeth_flood': 'Non-Spoofing', 'Mirai-greip_flood': 'Non-Spoofing', 'Mirai-udpplain': 'Non-Spoofing', \n",
    "                      'Recon-PingSweep': 'Non-Spoofing', 'Recon-OSScan': 'Non-Spoofing', 'Recon-PortScan': 'Non-Spoofing', 'VulnerabilityScan': 'Non-Spoofing', 'Recon-HostDiscovery': 'Non-Spoofing', \n",
    "                      'DNS_Spoofing': 'Spoofing', 'MITM-ArpSpoofing': 'Spoofing', \n",
    "                      'BenignTraffic': 'Non-Spoofing', \n",
    "                      'BrowserHijacking': 'Non-Spoofing', 'Backdoor_Malware': 'Non-Spoofing', 'XSS': 'Non-Spoofing', 'Uploading_Attack': 'Non-Spoofing', 'SqlInjection': 'Non-Spoofing', 'CommandInjection': 'Non-Spoofing', \n",
    "                      'DictionaryBruteForce': 'Non-Spoofing'}\n",
    "\n",
    "# Benign :\n",
    "dict_2classes_Benign = {'DDoS-RSTFINFlood': 'Non-Benign', 'DDoS-PSHACK_Flood': 'Non-Benign', 'DDoS-SYN_Flood': 'Non-Benign', 'DDoS-UDP_Flood': 'Non-Benign', 'DDoS-TCP_Flood': 'Non-Benign', 'DDoS-ICMP_Flood': 'Non-Benign', 'DDoS-SynonymousIP_Flood': 'Non-Benign', 'DDoS-ACK_Fragmentation': 'Non-Benign', 'DDoS-UDP_Fragmentation': 'Non-Benign', 'DDoS-ICMP_Fragmentation': 'Non-Benign', 'DDoS-SlowLoris': 'Non-Benign', 'DDoS-HTTP_Flood': 'Non-Benign',\n",
    "                      'DoS-UDP_Flood': 'Non-Benign', 'DoS-SYN_Flood': 'Non-Benign', 'DoS-TCP_Flood': 'Non-Benign', 'DoS-HTTP_Flood': 'Non-Benign', \n",
    "                      'Mirai-greeth_flood': 'Non-Benign', 'Mirai-greip_flood': 'Non-Benign', 'Mirai-udpplain': 'Non-Benign', \n",
    "                      'Recon-PingSweep': 'Non-Benign', 'Recon-OSScan': 'Non-Benign', 'Recon-PortScan': 'Non-Benign', 'VulnerabilityScan': 'Non-Benign', 'Recon-HostDiscovery': 'Non-Benign', \n",
    "                      'DNS_Spoofing': 'Non-Benign', 'MITM-ArpSpoofing': 'Non-Benign', \n",
    "                      'BenignTraffic': 'Benign', \n",
    "                      'BrowserHijacking': 'Non-Benign', 'Backdoor_Malware': 'Non-Benign', 'XSS': 'Non-Benign', 'Uploading_Attack': 'Non-Benign', 'SqlInjection': 'Non-Benign', 'CommandInjection': 'Non-Benign', \n",
    "                      'DictionaryBruteForce': 'Non-Benign'}\n",
    "\n",
    "# Web :\n",
    "dict_2classes_Web = {'DDoS-RSTFINFlood': 'Non-Web', 'DDoS-PSHACK_Flood': 'Non-Web', 'DDoS-SYN_Flood': 'Non-Web', 'DDoS-UDP_Flood': 'Non-Web', 'DDoS-TCP_Flood': 'Non-Web', 'DDoS-ICMP_Flood': 'Non-Web', 'DDoS-SynonymousIP_Flood': 'Non-Web', 'DDoS-ACK_Fragmentation': 'Non-Web', 'DDoS-UDP_Fragmentation': 'Non-Web', 'DDoS-ICMP_Fragmentation': 'Non-Web', 'DDoS-SlowLoris': 'Non-Web', 'DDoS-HTTP_Flood': 'Non-Web',\n",
    "                      'DoS-UDP_Flood': 'Non-Web', 'DoS-SYN_Flood': 'Non-Web', 'DoS-TCP_Flood': 'Non-Web', 'DoS-HTTP_Flood': 'Non-Web', \n",
    "                      'Mirai-greeth_flood': 'Non-Web', 'Mirai-greip_flood': 'Non-Web', 'Mirai-udpplain': 'Non-Web', \n",
    "                      'Recon-PingSweep': 'Non-Web', 'Recon-OSScan': 'Non-Web', 'Recon-PortScan': 'Non-Web', 'VulnerabilityScan': 'Non-Web', 'Recon-HostDiscovery': 'Non-Web', \n",
    "                      'DNS_Spoofing': 'Non-Web', 'MITM-ArpSpoofing': 'Non-Web', \n",
    "                      'BenignTraffic': 'Non-Web', \n",
    "                      'BrowserHijacking': 'Web', 'Backdoor_Malware': 'Web', 'XSS': 'Web', 'Uploading_Attack': 'Web', 'SqlInjection': 'Web', 'CommandInjection': 'Web', \n",
    "                      'DictionaryBruteForce': 'Non-Web'}\n",
    "\n",
    "# BruteForce :\n",
    "dict_2classes_BruteForce = {'DDoS-RSTFINFlood': 'Non-BruteForce', 'DDoS-PSHACK_Flood': 'Non-BruteForce', 'DDoS-SYN_Flood': 'Non-BruteForce', 'DDoS-UDP_Flood': 'Non-BruteForce', 'DDoS-TCP_Flood': 'Non-BruteForce', 'DDoS-ICMP_Flood': 'Non-BruteForce', 'DDoS-SynonymousIP_Flood': 'Non-BruteForce', 'DDoS-ACK_Fragmentation': 'Non-BruteForce', 'DDoS-UDP_Fragmentation': 'Non-BruteForce', 'DDoS-ICMP_Fragmentation': 'Non-BruteForce', 'DDoS-SlowLoris': 'Non-BruteForce', 'DDoS-HTTP_Flood': 'Non-BruteForce',\n",
    "                      'DoS-UDP_Flood': 'Non-BruteForce', 'DoS-SYN_Flood': 'Non-BruteForce', 'DoS-TCP_Flood': 'Non-BruteForce', 'DoS-HTTP_Flood': 'Non-BruteForce', \n",
    "                      'Mirai-greeth_flood': 'Non-BruteForce', 'Mirai-greip_flood': 'Non-BruteForce', 'Mirai-udpplain': 'Non-BruteForce', \n",
    "                      'Recon-PingSweep': 'Non-BruteForce', 'Recon-OSScan': 'Non-BruteForce', 'Recon-PortScan': 'Non-BruteForce', 'VulnerabilityScan': 'Non-BruteForce', 'Recon-HostDiscovery': 'Non-BruteForce', \n",
    "                      'DNS_Spoofing': 'Non-BruteForce', 'MITM-ArpSpoofing': 'Non-BruteForce', \n",
    "                      'BenignTraffic': 'Non-BruteForce', \n",
    "                      'BrowserHijacking': 'Non-BruteForce', 'Backdoor_Malware': 'Non-BruteForce', 'XSS': 'Non-BruteForce', 'Uploading_Attack': 'Non-BruteForce', 'SqlInjection': 'Non-BruteForce', 'CommandInjection': 'Non-BruteForce', \n",
    "                      'DictionaryBruteForce': 'BruteForce'}\n",
    "\n",
    "dict_2classes = [{\"dict_2classes\": dict_2classes_DDoS, \"type\": \"DDoS\"}, {\"dict_2classes\": dict_2classes_DoS, \"type\": \"DoS\"}, {\"dict_2classes\": dict_2classes_Mirai, \"type\": \"Mirai\"}, {\"dict_2classes\": dict_2classes_Recon, \"type\": \"Recon\"}, {\"dict_2classes\": dict_2classes_Spoofing, \"type\": \"Spoofing\"}, {\"dict_2classes\": dict_2classes_Benign, \"type\": \"Benign\"}, {\"dict_2classes\": dict_2classes_Web, \"type\": \"Web\"}, {\"dict_2classes\": dict_2classes_BruteForce, \"type\": \"BruteForce\"}]\n",
    "print(dict_2classes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc9f2faf",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### DDoS (2 classes) #####\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 135/135 [06:53<00:00,  3.06s/it]\n",
      "100%|██████████| 34/34 [00:47<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### DecisionTreeClassifier DDoS (2 classes) #####\n",
      "accuracy_score:  0.9995984588634549\n",
      "recall_score:  0.9994938784073801\n",
      "precision_score:  0.999492544786964\n",
      "f1_score:  0.9994932115945829\n",
      "\n",
      "\n",
      "\n",
      "##### DoS (2 classes) #####\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 135/135 [04:07<00:00,  1.83s/it]\n",
      "100%|██████████| 34/34 [00:46<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### DecisionTreeClassifier DoS (2 classes) #####\n",
      "accuracy_score:  0.9998533871958086\n",
      "recall_score:  0.999734935392105\n",
      "precision_score:  0.9997534472254663\n",
      "f1_score:  0.9997441910222378\n",
      "\n",
      "\n",
      "\n",
      "##### Mirai (2 classes) #####\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 135/135 [05:26<00:00,  2.42s/it]\n",
      "100%|██████████| 34/34 [00:47<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### DecisionTreeClassifier Mirai (2 classes) #####\n",
      "accuracy_score:  0.9999609290416271\n",
      "recall_score:  0.9998077545615813\n",
      "precision_score:  0.9998254662909732\n",
      "f1_score:  0.9998166102481232\n",
      "\n",
      "\n",
      "\n",
      "##### Recon (2 classes) #####\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 135/135 [07:05<00:00,  3.15s/it]\n",
      "100%|██████████| 34/34 [00:47<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### DecisionTreeClassifier Recon (2 classes) #####\n",
      "accuracy_score:  0.9969604922012336\n",
      "recall_score:  0.8999832346191019\n",
      "precision_score:  0.8981810623023343\n",
      "f1_score:  0.8990800783175715\n",
      "\n",
      "\n",
      "\n",
      "##### Spoofing (2 classes) #####\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 135/135 [04:33<00:00,  2.02s/it]\n",
      "100%|██████████| 34/34 [00:47<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### DecisionTreeClassifier Spoofing (2 classes) #####\n",
      "accuracy_score:  0.9962889359266263\n",
      "recall_score:  0.9057595694217162\n",
      "precision_score:  0.9169927923623553\n",
      "f1_score:  0.9112976416738859\n",
      "\n",
      "\n",
      "\n",
      "##### Benign (2 classes) #####\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 135/135 [05:07<00:00,  2.28s/it]\n",
      "100%|██████████| 34/34 [00:46<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### DecisionTreeClassifier Benign (2 classes) #####\n",
      "accuracy_score:  0.9957698917840835\n",
      "recall_score:  0.9534527451598984\n",
      "precision_score:  0.9546202621998258\n",
      "f1_score:  0.9540357131744854\n",
      "\n",
      "\n",
      "\n",
      "##### Web (2 classes) #####\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 135/135 [06:05<00:00,  2.71s/it]\n",
      "100%|██████████| 34/34 [00:46<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### DecisionTreeClassifier Web (2 classes) #####\n",
      "accuracy_score:  0.9993841488541619\n",
      "recall_score:  0.7114222214878461\n",
      "precision_score:  0.7366239492943202\n",
      "f1_score:  0.7233130349957493\n",
      "\n",
      "\n",
      "\n",
      "##### BruteForce (2 classes) #####\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 135/135 [05:17<00:00,  2.35s/it]\n",
      "100%|██████████| 34/34 [00:51<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### DecisionTreeClassifier BruteForce (2 classes) #####\n",
      "accuracy_score:  0.9997076447842543\n",
      "recall_score:  0.7471431943606167\n",
      "precision_score:  0.7960909409847152\n",
      "f1_score:  0.7694098832870624\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ML_models = [\n",
    "        DecisionTreeClassifier(),\n",
    "        # RandomForestClassifier(n_jobs=-1),\n",
    "        # GradientBoostingClassifier(),\n",
    "        # LogisticRegression(n_jobs=-1),\n",
    "]\n",
    "\n",
    "ML_neams = [\n",
    "        \"DecisionTreeClassifier\",\n",
    "        # \"RandomForestClassifier\",\n",
    "        # \"GradientBoostingClassifier\",\n",
    "        # \"LogisticRegression\",\n",
    "]\n",
    "\n",
    "# Itération sur chaque objet du dictionnaire\n",
    "for dict_item in dict_2classes:\n",
    "        print(f\"##### {dict_item['type']} (2 classes) #####\")\n",
    "        print()\n",
    "        print()\n",
    "        # Extraire le dictionnaire dict_2classes et le type associé\n",
    "        dict_2classes = dict_item[\"dict_2classes\"]\n",
    "        type_name = dict_item[\"type\"]\n",
    "\n",
    "        # For each dataset\n",
    "        for train_set in tqdm(training_sets):\n",
    "        \n",
    "                # Load the dataset in memory\n",
    "                d = pd.read_csv(DATASET_DIRECTORY + train_set)\n",
    "\n",
    "                # Normalize the data\n",
    "                d[X_columns] = scaler.transform(d[X_columns])\n",
    "\n",
    "                # Update the labels of the target variable\n",
    "                new_y = [dict_2classes[k] for k in d[y_column]]\n",
    "                d[y_column] = new_y\n",
    "                \n",
    "                # For each model\n",
    "                for model in (ML_models):\n",
    "\n",
    "                        # Train the model\n",
    "                        model.fit(d[X_columns], d[y_column])\n",
    "\n",
    "                # Delete the dataset from memory\n",
    "                del d\n",
    "\n",
    "        # Initialisation d'une liste pour stocker les vraies valeurs de la variable cible (classe) pour l'ensemble de test.\n",
    "        y_test = []\n",
    "\n",
    "        # Initialisation d'un dictionnaire pour stocker les prédictions de chaque modèle.\n",
    "        # Les clés du dictionnaire sont les indices des modèles.\n",
    "        preds = {i: [] for i in range(len(ML_models))}\n",
    "\n",
    "        # Itération sur chaque ensemble de test contenu dans la liste test_sets.\n",
    "        for test_set in tqdm(test_sets):\n",
    "                # Chargement d'un fichier CSV correspondant à l'ensemble de test actuel dans un DataFrame pandas d_test.\n",
    "                d_test = pd.read_csv(DATASET_DIRECTORY + test_set)\n",
    "\n",
    "                # Mise à l'échelle des colonnes d'entités de d_test à l'aide d'un objet scaler.\n",
    "                # Cela permet de mettre à l'échelle les données de test de la même manière que les données d'entraînement.\n",
    "                d_test[X_columns] = scaler.transform(d_test[X_columns])\n",
    "\n",
    "                # Création d'une nouvelle liste new_y en associant chaque valeur de d_test[y_column]\n",
    "                # aux valeurs correspondantes dans le dictionnaire dict_2classes.\n",
    "                # Cela permet de mapper les étiquettes d'origine aux classes utilisées pour l'évaluation.\n",
    "                new_y = [dict_2classes[k] for k in d_test[y_column]]\n",
    "\n",
    "                # Remplacement de la colonne de la variable cible y_column dans d_test par les nouvelles étiquettes new_y.\n",
    "                d_test[y_column] = new_y\n",
    "\n",
    "                # Extension de la liste y_test avec les valeurs de la variable cible transformée pour l'ensemble de test actuel.\n",
    "                y_test += list(d_test[y_column].values)\n",
    "\n",
    "                # Itération sur chaque modèle contenu dans la liste ML_models.\n",
    "                for i in range(len(ML_models)):\n",
    "                        # Sélection du modèle actuel à évaluer.\n",
    "                        model = ML_models[i]\n",
    "\n",
    "                        # Utilisation du modèle pour faire des prédictions sur l'ensemble de test actuel.\n",
    "                        y_pred = list(model.predict(d_test[X_columns]))\n",
    "                        \n",
    "                        # Stockage des prédictions du modèle actuel dans la liste correspondante du dictionnaire preds.\n",
    "                        preds[i] = preds[i] + y_pred\n",
    "\n",
    "        # Initialize the list of true labels\n",
    "        for k,v in preds.items():\n",
    "                # Save model\n",
    "                joblib.dump(ML_models[k], f\".\\Models\\model_{ML_neams[k]}_{dict_item['type']}.joblib\")\n",
    "\n",
    "                y_pred = v\n",
    "                print(f\"##### {ML_neams[k]} {dict_item['type']} (2 classes) #####\")\n",
    "                print('accuracy_score: ', accuracy_score(y_pred, y_test))\n",
    "                print('recall_score: ', recall_score(y_pred, y_test, average='macro'))\n",
    "                print('precision_score: ', precision_score(y_pred, y_test, average='macro'))\n",
    "                print('f1_score: ', f1_score(y_pred, y_test, average='macro'))\n",
    "                print()\n",
    "                print()\n",
    "                print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e02a88",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "78f35629",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:44<00:00,  5.53s/it]\n"
     ]
    }
   ],
   "source": [
    "ML_models = [\n",
    "        DecisionTreeClassifier(),\n",
    "        # RandomForestClassifier(n_jobs=-1),\n",
    "        # GradientBoostingClassifier(),\n",
    "        # LogisticRegression(n_jobs=-1),\n",
    "]\n",
    "\n",
    "ML_neams = [\n",
    "        \"DecisionTreeClassifier\",\n",
    "        # \"RandomForestClassifier\",\n",
    "        # \"GradientBoostingClassifier\",\n",
    "        # \"LogisticRegression\",\n",
    "]\n",
    "\n",
    "# Load last model\n",
    "# modelName = \"DecisionTreeClassifier\"\n",
    "# loaded_model = joblib.load(f\".\\Models\\model_{modelName}_DDoS.joblib\")\n",
    "# ML_models.append(loaded_model)\n",
    "# ML_neams.append(modelName)\n",
    "\n",
    "# For each dataset\n",
    "for train_set in tqdm(training_sets):\n",
    "    \n",
    "    # Load the dataset in memory\n",
    "    d = pd.read_csv(DATASET_DIRECTORY + train_set)\n",
    "\n",
    "    # Normalize the data\n",
    "    d[X_columns] = scaler.transform(d[X_columns])\n",
    "\n",
    "    # Update the labels of the target variable\n",
    "    new_y = [dict_2classes[k] for k in d[y_column]]\n",
    "    d[y_column] = new_y\n",
    "    \n",
    "    # For each model\n",
    "    for model in (ML_models):\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(d[X_columns], d[y_column])\n",
    "\n",
    "    # Delete the dataset from memory\n",
    "    del d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "32a21f58",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:03<00:00,  1.80s/it]\n"
     ]
    }
   ],
   "source": [
    "# Initialisation d'une liste pour stocker les vraies valeurs de la variable cible (classe) pour l'ensemble de test.\n",
    "y_test = []\n",
    "\n",
    "# Initialisation d'un dictionnaire pour stocker les prédictions de chaque modèle.\n",
    "# Les clés du dictionnaire sont les indices des modèles.\n",
    "preds = {i: [] for i in range(len(ML_models))}\n",
    "\n",
    "# Itération sur chaque ensemble de test contenu dans la liste test_sets.\n",
    "for test_set in tqdm(test_sets):\n",
    "    # Chargement d'un fichier CSV correspondant à l'ensemble de test actuel dans un DataFrame pandas d_test.\n",
    "    d_test = pd.read_csv(DATASET_DIRECTORY + test_set)\n",
    "    \n",
    "    # Mise à l'échelle des colonnes d'entités de d_test à l'aide d'un objet scaler.\n",
    "    # Cela permet de mettre à l'échelle les données de test de la même manière que les données d'entraînement.\n",
    "    d_test[X_columns] = scaler.transform(d_test[X_columns])\n",
    "\n",
    "    # Création d'une nouvelle liste new_y en associant chaque valeur de d_test[y_column]\n",
    "    # aux valeurs correspondantes dans le dictionnaire dict_2classes.\n",
    "    # Cela permet de mapper les étiquettes d'origine aux classes utilisées pour l'évaluation.\n",
    "    new_y = [dict_2classes[k] for k in d_test[y_column]]\n",
    "    \n",
    "    # Remplacement de la colonne de la variable cible y_column dans d_test par les nouvelles étiquettes new_y.\n",
    "    d_test[y_column] = new_y\n",
    "    \n",
    "    # Extension de la liste y_test avec les valeurs de la variable cible transformée pour l'ensemble de test actuel.\n",
    "    y_test += list(d_test[y_column].values)\n",
    "    \n",
    "    # Itération sur chaque modèle contenu dans la liste ML_models.\n",
    "    for i in range(len(ML_models)):\n",
    "        # Sélection du modèle actuel à évaluer.\n",
    "        model = ML_models[i]\n",
    "\n",
    "        # Utilisation du modèle pour faire des prédictions sur l'ensemble de test actuel.\n",
    "        y_pred = list(model.predict(d_test[X_columns]))\n",
    "        \n",
    "        # Stockage des prédictions du modèle actuel dans la liste correspondante du dictionnaire preds.\n",
    "        preds[i] = preds[i] + y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "65d2bbbf",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### DecisionTreeClassifier (2 classes) #####\n",
      "accuracy_score:  0.9996729564525692\n",
      "recall_score:  0.9995829511618257\n",
      "precision_score:  0.9995902588168041\n",
      "f1_score:  0.9995866049119663\n",
      "\n",
      "\n",
      "\n",
      "##### DecisionTreeClassifier (2 classes) #####\n",
      "accuracy_score:  0.999656076785605\n",
      "recall_score:  0.9995324226102099\n",
      "precision_score:  0.9995981775667151\n",
      "f1_score:  0.9995652938243755\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the list of true labels\n",
    "for k,v in preds.items():\n",
    "    # Save model\n",
    "    joblib.dump(ML_models[k], f\".\\Models\\model_{ML_neams[k]}_DDoS.joblib\")\n",
    "\n",
    "    y_pred = v\n",
    "    print(f\"##### {ML_neams[k]} (2 classes) #####\")\n",
    "    print('accuracy_score: ', accuracy_score(y_pred, y_test))\n",
    "    print('recall_score: ', recall_score(y_pred, y_test, average='macro'))\n",
    "    print('precision_score: ', precision_score(y_pred, y_test, average='macro'))\n",
    "    print('f1_score: ', f1_score(y_pred, y_test, average='macro'))\n",
    "    print()\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1808fe",
   "metadata": {},
   "source": [
    "# Results for classification DDoS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfcfa83",
   "metadata": {},
   "source": [
    "##### DecisionTreeClassifier (2 classes) #####\n",
    "- accuracy_score:  0.999656076785605\n",
    "- recall_score:  0.9995397188023061\n",
    "- precision_score:  0.9995908637100563\n",
    "- f1_score:  0.9995652874666482\n",
    "\n",
    "##### RandomForestClassifier (2 classes) #####\n",
    "- accuracy_score:  0.9995421390335969\n",
    "- recall_score:  0.9993835583640872\n",
    "- precision_score:  0.9994590309032679\n",
    "- f1_score:  0.999421286377896\n",
    "\n",
    "##### GradientBoostingClassifier (2 classes) #####\n",
    "- accuracy_score:  0.9996138776181946\n",
    "- recall_score:  0.9995253081576231\n",
    "- precision_score:  0.9994985147827335\n",
    "- f1_score:  0.9995119104302792\n",
    "\n",
    "##### LogisticRegression (2 classes) #####\n",
    "- accuracy_score:  0.8466566654639904\n",
    "- recall_score:  0.8835917015235932\n",
    "- precision_score:  0.7278965042927341\n",
    "- f1_score:  0.7636924766683586"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e515a46",
   "metadata": {},
   "source": [
    "# Memory cleanning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "919c026d",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
